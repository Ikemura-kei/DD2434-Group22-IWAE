# IWAE objectives

import numpy as np
import torch
import torch.distributions as dists
from torch import nn

class IWAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=200, latent_dim=20, K=50):
        super(IWAE, self).__init__()

        self.K = K

        self.img_2_hid = nn.Linear(input_dim, hidden_dim)
        self.hid_2_mu = nn.Linear(hidden_dim, latent_dim)
        self.hid_2_sigma = nn.Linear(hidden_dim, latent_dim)

        self.z_2_hid = nn.Linear(latent_dim, hidden_dim)
        self.hid_2_img = nn.Linear(hidden_dim, input_dim)

    def encoder(self, x): # q_phi(z|x)

        h = torch.tanh(self.img_2_hid(x))
        mu, sigma = self.hid_2_mu(h), self.hid_2_sigma(h)

        return mu, sigma

    def decoder(self, z): # p_theta(x|z)

        h = torch.tanh(self.z_2_hid(z))
        recon_x = torch.sigmoid(self.hid_2_img(h)) # Pixel value should be between 0 and 1

        return recon_x
    
    def forward(self, x):

        mu, sigma = self.encoder(x)
        eps = torch.randn_like(sigma)
        repar_z = mu + sigma * eps
        recon_x = self.decoder(repar_z)

        return recon_x, repar_z, mu, sigma

    def iwae_loss(self, x):

        # Collect K samples
        recon_x, repar_z, mu, sigma = self.forward(self, x)
        mu_sampled = mu.unsqueeze(1).repeat(1, self.K, 1) # [batch, sample_num, dim]
        sigma_sampled = sigma.unsqueeze(1).repeat(1, self.K, 1)
        x_sampled = x.unsqueeze(1).repeat(1, self.K, 1, 1, 1) # [batch, sample_num, channels, dim, dim]?

        # Compute unnormalized log weights [batch, sample_num]
        log_p_x_given_z = dists.Bernoulli(recon_x).log_prob(x_sampled).sum(axis=(2, 3, 4))
        log_p_z = dists.Normal(0, 1).log_prob(repar_z).sum(2)
        log_q_z_given_x = dists.Normal(mu_sampled, sigma_sampled).log_prob(repar_z).sum(2)
        log_importance_weight = log_p_x_given_z - log_q_z_given_x + log_p_z

        # Compute IWAE loss [batch] -> scalar
        log_marginal_likelihood = (torch.logsumexp(log_importance_weight, 1) - np.log(self.K)).mean() # mean over batch
        iwae_loss = - log_marginal_likelihood

        return iwae_loss





if __name__ == "__main__":
    x = torch.randn(4, 784) # batch size, 28*28
    iwae = IWAE()
    re_x, mu, sigma = iwae(x)
    print(re_x.shape)
    print(mu.shape)
    print(sigma.shape)





# MNIST data prep
# import torchvision.datasets as datasets
# from torch.utils.data import DataLoader
# from torchvision import transforms
# dataset = datasets.MNIST(root="dataset/", train=True, transform=transforms.ToTensor(), download=True)
# train_loader = DataLoader(dataset=dataset, batch_size= BATCH_SIZE, shuffle=True)
